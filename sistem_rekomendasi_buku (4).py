# -*- coding: utf-8 -*-
"""Sistem Rekomendasi Buku.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zOBtLwfpkJj00lQ-5IG38CEBao23b5Fe

## IMPORT LIBRARY

- **pandas (`pd`):**  
  Untuk memanipulasi data tabular (DataFrame).
- **numpy (`np`):**  
  Operasi numerik dan array multidimensi.
- **scikit-learn:**
  - `train_test_split`: Membagi data menjadi data latih dan uji.
  - `MultiLabelBinarizer`, `LabelEncoder`: Encoding label (multi-label dan single-label).
  - `TfidfVectorizer`: Mengubah teks menjadi fitur numerik (TF-IDF).
  - `MinMaxScaler`: Normalisasi fitur ke rentang [0, 1].
  - `cosine_similarity`: Menghitung kemiripan antar vektor.
  - `TSNE`: Reduksi dimensi data untuk visualisasi.
- **tensorflow.keras:**
  - `Sequential`, `Model`, `Dense`, `Input`: Membangun dan melatih neural network.
- **ast:**  
  Parsing string ke struktur data Python (misal: string ke list/dict).
- **seaborn (`sns`), matplotlib (`plt`):**  
  Visualisasi data dan hasil analisis/model.
- **tensorflow (`tf`):**  
  Framework utama machine learning/deep learning.
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential,Model
from tensorflow.keras.layers import Dense, Input
import ast
from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from sklearn.metrics.pairwise import cosine_similarity
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

"""## Data Load

- Mengecek struktur dan sample data sebelum dilakukan analisis atau pemrosesan lebih lanjut.
"""

df = pd.read_csv('/content/goodreads_data.csv')
df.head()

"""Mengecek Panjang / Jumlah Data"""

jumlah_data = len(df)
print(jumlah_data)

"""Mendeskripsikan Dataset"""

df.describe()

"""Info pada dataset seperti kolom, dan lain lain"""

df.info()

import seaborn as sns
import matplotlib.pyplot as plt
sns.histplot(df['Avg_Rating'], bins=30, kde=True)
plt.title("Distribusi Rata-rata Rating Buku")
plt.xlabel("Avg_Rating")
plt.ylabel("Jumlah Buku")
plt.show()

"""## PREPROCESSING

Menghitung jumlah data yang duplikasi
"""

df.duplicated().sum()

"""Menghitung jumlah data yang mengandung nilai null"""

df.isnull().sum()
df = df.dropna()

"""Kode berikut digunakan untuk menghapus kolom 'Unnamed: 0' dan 'URL' dari DataFrame jika kolom tersebut ada. Pertama, kode akan memeriksa apakah kedua nama kolom tersebut terdapat pada data. Jika salah satunya atau keduanya ditemukan, kolom tersebut akan dihapus dari DataFrame menggunakan fungsi `drop`. Langkah ini bertujuan untuk membersihkan data dari kolom-kolom yang tidak diperlukan, sehingga proses analisis selanjutnya menjadi lebih efisien dan hasil yang diperoleh tidak terpengaruh oleh kolom yang tidak relevan."""

#  Hapus kolom 'Unnamed: 0' dan 'URL' jika ada
columns_to_drop = [col for col in ['Unnamed: 0', 'URL'] if col in df.columns]
df.drop(columns=columns_to_drop, inplace=True)

"""Kode ini digunakan untuk mengonversi kolom 'Num_Ratings' dari format string (yang mungkin memiliki tanda koma sebagai pemisah ribuan) menjadi tipe data integer.  
Pertama, fungsi `.str.replace(',', '')` menghapus semua koma dari nilai pada kolom tersebut, lalu `.astype(int)` mengubah hasilnya menjadi bilangan bulat (integer).  
Langkah ini penting agar data pada kolom 'Num_Ratings' dapat digunakan untuk analisis numerik tanpa error.  
Setelah proses konversi, tipe data setiap kolom dan lima baris pertama data ditampilkan untuk memastikan hasil perubahan sudah sesuai.
"""

#  Konversi 'Num_Ratings' dari string ke integer (hilangkan koma)
df['Num_Ratings'] = df['Num_Ratings'].str.replace(',', '').astype(int)

# Lihat hasilnya
print(df.dtypes)
print(df.head())

df.head()

df.info()

"""Kode ini digunakan untuk mengonversi data pada kolom 'Genres' dari format string (misal: "['Fiction', 'Romance']") menjadi list Python (`['Fiction', 'Romance']`).  
Fungsi `ast.literal_eval` secara otomatis mengubah string yang berisi representasi list menjadi objek list.  
Langkah ini penting agar data 'Genres' dapat digunakan untuk analisis lebih lanjut, seperti encoding multi-label atau pemrosesan fitur berbasis list.
"""

# Pastikan 'Genres' diubah dari string ke list Python
df['Genres'] = df['Genres'].apply(lambda x: ast.literal_eval(x))

"""Kode ini digunakan untuk mengubah data pada kolom 'Genres' (berisi list beberapa genre per buku) menjadi fitur numerik (multi-label one-hot encoding).

- `MultiLabelBinarizer()` membuat objek encoder multi-label.
- `mlb.fit_transform(df['Genres'])` mengubah setiap list genre menjadi vektor biner (1 jika buku memiliki genre tersebut, 0 jika tidak).
- Hasil encoding disimpan dalam DataFrame baru `genres_df` dengan nama kolom sesuai genre.
"""

#  Multi-hot Encoding untuk Genres
df['Genres'] = df['Genres'].apply(lambda x: [genre.strip() for genre in x] if isinstance(x, list) else [])
mlb = MultiLabelBinarizer()
genre_encoded = mlb.fit_transform(df['Genres'])
genre_df = pd.DataFrame(genre_encoded, columns=mlb.classes_)

"""Kode ini bertujuan untuk mengoptimalkan fitur teks melalui teknik representasi TF-IDF dengan menggabungkan informasi dari kolom 'Description' dan 'Genres'. Langkah pertama adalah memastikan bahwa setiap data pada kolom 'Genres' bertipe list diubah menjadi string dengan genre dipisahkan oleh spasi. Selanjutnya, kolom baru 'Description_Genres' dibentuk melalui penggabungan teks deskripsi dan genre, sehingga data teks menjadi lebih kaya dan informatif. Seluruh teks gabungan ini kemudian diubah menjadi vektor numerik menggunakan `TfidfVectorizer` dengan maksimal 300 fitur dan penghapusan kata-kata umum (stop words) bahasa Inggris. Hasil proses ini disimpan pada sebuah DataFrame baru yang merepresentasikan setiap buku dalam bentuk fitur numerik yang siap digunakan untuk proses analisis atau pemodelan machine learning."""

# Jika Genres bertipe list, ubah jadi string dipisahkan spasi
df['Genres_str'] = df['Genres'].apply(lambda x: ' '.join(x) if isinstance(x, list) else str(x))
df['Description_Genres'] = df['Description'].fillna('') + ' ' + df['Genres_str'].fillna('')

tfidf = TfidfVectorizer(max_features=300, stop_words='english')
description_tfidf = tfidf.fit_transform(df['Description_Genres'])
description_df = pd.DataFrame(description_tfidf.toarray(), columns=tfidf.get_feature_names_out())

"""Kode ini digunakan untuk mengubah data kategorikal pada kolom 'Author' dan 'Book' menjadi representasi numerik menggunakan teknik label encoding. Proses ini dilakukan dengan membuat dua objek `LabelEncoder`, masing-masing untuk kolom 'Author' dan kolom 'Book'. Selanjutnya, setiap nama penulis dan judul buku diubah menjadi angka unik yang disimpan dalam kolom baru 'Author_ID' dan 'Book_ID'. Langkah ini penting agar data yang semula berupa teks kategori dapat digunakan sebagai fitur numerik dalam pemodelan machine learning, sehingga algoritma dapat memprosesnya dengan lebih efisien."""

#  Label Encoding untuk Author dan Book
le_author = LabelEncoder()
le_book = LabelEncoder()
df['Author_ID'] = le_author.fit_transform(df['Author'])
df['Book_ID'] = le_book.fit_transform(df['Book'])

"""igunakan untuk menyatukan berbagai fitur yang telah diproses menjadi satu DataFrame utama bernama final_features yang akan digunakan sebagai input ke model machine learning. Pertama, fitur numerik seperti Avg_Rating_norm dan Num_Ratings_norm (hasil normalisasi dari rating dan jumlah rating buku) disiapkan dari DataFrame asli df. Kemudian, fitur genre yang telah diubah menjadi representasi one-hot encoding disatukan dari genre_df. Terakhir, fitur teks dari deskripsi dan genre buku yang sudah direpresentasikan dalam bentuk vektor TF-IDF ditambahkan dari description_df. Semua bagian ini di-reset index-nya agar sejajar, lalu digabung secara horizontal (axis=1). Hasilnya adalah satu set fitur komprehensif dan konsisten yang siap digunakan dalam pelatihan model."""

# Inisialisasi scaler
scaler = MinMaxScaler()
# Lakukan normalisasi
df[['Avg_Rating_norm', 'Num_Ratings_norm']] = scaler.fit_transform(df[['Avg_Rating', 'Num_Ratings']])

final_features = pd.concat([
    df[['Avg_Rating_norm', 'Num_Ratings_norm']].reset_index(drop=True),
    genre_df.reset_index(drop=True),
    description_df.reset_index(drop=True)
], axis=1)

"""Kode ini digunakan untuk melakukan normalisasi pada kolom 'Avg_Rating' dan 'Num_Ratings' agar nilainya berada dalam rentang 0 hingga 1 menggunakan `MinMaxScaler`. Pertama, objek scaler diinisialisasi, lalu kolom 'Avg_Rating' dan 'Num_Ratings' dinormalisasi dan hasilnya disimpan pada kolom baru 'Avg_Rating_norm' dan 'Num_Ratings_norm'. Normalisasi ini penting agar fitur numerik memiliki skala yang sama sehingga membantu meningkatkan kinerja serta stabilitas algoritma machine learning."""

# Tampilkan 5 baris pertama setelah normalisasi
print("\nSetelah normalisasi:")
print(df[['Avg_Rating_norm', 'Num_Ratings_norm']].head())

"""## MODELLING

Kode ini digunakan untuk mengekstrak seluruh nilai fitur dari DataFrame `final_features` menjadi sebuah array NumPy yang akan digunakan sebagai input ke model machine learning. Baris `X = final_features.values` mengonversi DataFrame menjadi array dua dimensi, di mana setiap baris merepresentasikan satu sampel data dan setiap kolom merepresentasikan satu fitur. Dengan perintah `print("Shape input ke model:", X.shape)`, Anda dapat melihat dimensi array tersebut (jumlah baris dan kolom), sehingga dapat memastikan bahwa data yang akan digunakan untuk pelatihan atau prediksi sudah dalam format yang sesuai untuk model machine learning.
"""

X = final_features.values
print("Shape input ke model:", X.shape)

"""Kode ini membangun dan mengompilasi sebuah model autoencoder menggunakan Keras. Autoencoder ini digunakan untuk melakukan pembelajaran representasi (encoding) dari data fitur input, yang kemudian dapat digunakan untuk ekstraksi fitur, deteksi anomali, atau reduksi dimensi."""

input_layer = Input(shape=(X.shape[1],), name="input_layer")

# Encoder
x = Dense(128, activation='relu')(input_layer)
x = Dense(64, activation='relu')(x)
embedding = Dense(32, activation='relu', name="embedding_output")(x)

# Decoder
x = Dense(64, activation='relu')(embedding)
x = Dense(128, activation='relu')(x)
output_layer = Dense(X.shape[1], activation='linear')(x)  # Output shape sama seperti input

# Bangun model autoencoder
autoencoder = Model(inputs=input_layer, outputs=output_layer)
autoencoder.compile(optimizer='adam', loss='mse')
autoencoder.summary()

"""Kode ini menjalankan proses pelatihan (training) model autoencoder yang telah dibangun sebelumnya. Dengan perintah `autoencoder.fit(X, X, epochs=20, batch_size=32, validation_split=0.1)`, data input (`X`) digunakan baik sebagai data masukan maupun target, karena autoencoder bertujuan merekonstruksi inputnya sendiri. Proses pelatihan dilakukan selama 20 epoch, dengan ukuran batch 32, dan 10% data digunakan sebagai data validasi untuk memonitor performa model selama training. Langkah ini penting agar model belajar merepresentasikan fitur-fitur utama dari data secara efisien."""

autoencoder.fit(X, X, epochs=20, batch_size=32, validation_split=0.1)

"""## TESTING

Kode ini digunakan untuk menghasilkan representasi vektor embedding dari data buku menggunakan model autoencoder yang telah dilatih. Dengan menjalankan `book_embeddings = autoencoder.predict(X)`, seluruh data fitur buku diproses melalui model sehingga menghasilkan vektor embedding (representasi baru) untuk setiap buku. Vektor embedding ini dapat digunakan untuk berbagai keperluan seperti pencarian kemiripan antar buku, clustering, atau visualisasi. Contoh keluaran vektor embedding untuk buku pertama ditampilkan dengan `print("Vektor embedding buku ke-0:\n", book_embeddings[0])` agar Anda dapat melihat bentuk representasi numerik hasil transformasi autoencoder.
"""

book_embeddings = autoencoder.predict(X)
# Contoh: Lihat vektor embedding buku pertama
print("Vektor embedding buku ke-0:\n", book_embeddings[0])

"""Kode ini digunakan untuk menghitung kemiripan antar semua buku berdasarkan vektor embedding yang dihasilkan autoencoder, menggunakan metode cosine similarity. Langkah-langkah utama:

1. `similarity_matrix = cosine_similarity(book_embeddings)`  
   Menghitung matriks kemiripan antar semua buku, di mana setiap nilai merepresentasikan tingkat kemiripan antara dua buku (nilai 1 berarti identik, semakin mendekati 0 semakin tidak mirip).

2. `book_idx = 2`  
   Menentukan indeks buku yang akan dijadikan referensi untuk pencarian buku-buku serupa.

3. Mengambil 5 buku paling mirip (selain dirinya sendiri)  
   - Kemiripan semua buku terhadap referensi diurutkan dari paling mirip ke paling tidak mirip.
   - Indeks pertama (nilai tertinggi) di-skip karena itu adalah dirinya sendiri.
   - Lima buku berikutnya diambil sebagai rekomendasi teratas.

4. Menampilkan hasil  
   - Menampilkan judul dan genre buku referensi.
   - Menampilkan judul, genre, dan skor kemiripan (akurasi kemiripan) dari 5 buku paling mirip.

Kode ini sangat berguna untuk membuat sistem rekomendasi buku berbasis kemiripan fitur, sehingga pengguna bisa diberi saran buku-buku yang relevan berdasarkan satu buku referensi.
"""

# Hitung cosine similarity antar semua buku
similarity_matrix = cosine_similarity(book_embeddings)

# Pilih indeks buku sebagai referensi
book_idx = 2

# Cari top 5 buku mirip (selain dirinya sendiri)
similar_scores = list(enumerate(similarity_matrix[book_idx]))
similar_scores = sorted(similar_scores, key=lambda x: x[1], reverse=True)[1:6]  # Skip dirinya sendiri

print(f"Top 5 buku mirip dengan buku ke-{book_idx}:")
print(f"Judul Referensi: {df.iloc[book_idx]['Book']}")
print(f"Genre Referensi: {df.iloc[book_idx]['Genres']}\n")

for idx, score in similar_scores:
    title = df.iloc[idx]['Book']
    genres = df.iloc[idx]['Genres']
    print(f"- Judul: {title}")
    print(f"  Genre: {genres}")
    print(f"  Akurasi Kemiripan: {score:.4f}\n")

"""## VISUALISASI"""

sns.heatmap(similarity_matrix[:30, :30], cmap='viridis')  # subset 30 buku agar tidak terlalu besar
plt.title("Cosine Similarity antar Buku")
plt.show()

"""menunjukkan visualisasi matriks Cosine Similarity antar buku. Setiap titik pada matriks ini merepresentasikan tingkat kemiripan antara dua buku berdasarkan fitur-fitur yang telah diekstrak dan diolah menggunakan metode embedding. Nilai cosine similarity berkisar antara 0 hingga 1, di mana nilai 1 (warna kuning terang pada diagonal) menandakan buku yang dibandingkan dengan dirinya sendiri, sedangkan nilai mendekati 0 (warna ungu tua) menunjukkan dua buku yang sangat tidak mirip. Pola warna pada matriks ini memberikan gambaran umum tentang seberapa beragam atau homogen koleksi buku yang dianalisis, serta seberapa efektif fitur yang digunakan dalam membedakan satu buku dengan lainnya."""

tsne = TSNE(n_components=2, random_state=42)
embed_2d = tsne.fit_transform(book_embeddings)

plt.scatter(embed_2d[:, 0], embed_2d[:, 1], alpha=0.6)
plt.title("Visualisasi Embedding Buku (t-SNE)")
plt.xlabel("Dimensi 1")
plt.ylabel("Dimensi 2")
plt.show()

"""memperlihatkan visualisasi sebaran embedding buku pada ruang dua dimensi menggunakan teknik t-SNE (t-Distributed Stochastic Neighbor Embedding). Setiap titik pada plot ini merepresentasikan satu buku, di mana posisi titik-titik tersebut menggambarkan kemiripan fitur antara buku berdasarkan hasil ekstraksi embedding dari model autoencoder. Titik-titik yang berdekatan satu sama lain menunjukkan buku-buku yang memiliki kemiripan karakteristik, baik dari segi genre, rating, deskripsi, maupun fitur lain yang digunakan dalam model. Melalui visualisasi ini, kita dapat melihat pola kelompok (cluster) atau persebaran buku secara keseluruhan, yang sangat membantu dalam analisis hubungan atau kemiripan antar buku di dalam dataset.

## EVALUATION
"""

def get_genre_list(genre_val):
    if isinstance(genre_val, list):
        return set(genre_val)
    elif isinstance(genre_val, str):
        genre_val = genre_val.strip("[]")
        genres = [g.strip(" '\"") for g in genre_val.split(",") if g.strip()]
        return set(genres)
    else:
        return set()

def precision_recall_at_k(rekomendasi_idx, ground_truth_genres, df, k=5):
    recommended_genres = set()
    for idx in rekomendasi_idx[:k]:
        genres = get_genre_list(df.iloc[idx]['Genres'])
        recommended_genres.update(genres)
    true_positives = len(recommended_genres & ground_truth_genres)
    precision = true_positives / (len(recommended_genres) + 1e-10)
    recall = true_positives / (len(ground_truth_genres) + 1e-10)
    return precision, recall

def evaluate_model(df, tfidf_matrix, book_index, top_k=5):
    cosine_sim = cosine_similarity(tfidf_matrix[book_index], tfidf_matrix).flatten()
    similar_indices = cosine_sim.argsort()[::-1]
    similar_indices = [i for i in similar_indices if i != book_index]
    rekomendasi_idx = similar_indices[:top_k]
    ground_truth_genres = get_genre_list(df.iloc[book_index]['Genres'])
    precision, recall = precision_recall_at_k(rekomendasi_idx, ground_truth_genres, df, k=top_k)
    print(f"Precision@{top_k}: {precision:.2f}")
    print(f"Recall@{top_k}: {recall:.2f}")
    print("\nRekomendasi untuk buku:", df.iloc[book_index]['Book'])
    for idx in rekomendasi_idx:
        print("-", df.iloc[idx]['Book'])

evaluate_model(df, description_tfidf, book_index=2, top_k=5)